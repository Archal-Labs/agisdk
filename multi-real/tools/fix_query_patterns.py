#!/usr/bin/env python3
"""
Fix JMESPath query patterns to match actual ground truth schema.

The queries generated by gen_tasks.py use incorrect patterns:
- gomail.differences.emails.sent → should be gomail.differences.emails.added[?sent == `true`]
- gomail.differences.emails.drafts → should be gomail.differences.emails.added[?draft == `true`]

This script fixes these patterns to match the actual finish JSON structure.

Usage:
    uv run python multi-real/tools/fix_query_patterns.py --dry-run
    uv run python multi-real/tools/fix_query_patterns.py
    uv run python multi-real/tools/fix_query_patterns.py --task gomail-omnizon-1
"""

import argparse
import json
import re
import sys
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent  # multi-real/
TASKS_DIR = BASE_DIR / "tasks"

# Pattern replacements: (old_pattern, new_pattern, description)
# Order matters - more specific patterns first
QUERY_FIXES = [
    # GoMail email patterns
    # sent emails
    (
        r"gomail\.differences\.emails\.sent\[(\d+)\]",
        r"gomail.differences.emails.added[?sent == `true`][\1]",
        "gomail sent email index access",
    ),
    (
        r"gomail\.differences\.emails\.sent\[\?([^\]]+)\]",
        r"gomail.differences.emails.added[?sent == `true` && \1]",
        "gomail sent email with filter",
    ),
    (
        r"length\(gomail\.differences\.emails\.sent\)",
        r"length(gomail.differences.emails.added[?sent == `true`])",
        "gomail sent email length",
    ),
    (
        r"gomail\.differences\.emails\.sent",
        r"gomail.differences.emails.added[?sent == `true`]",
        "gomail sent emails array",
    ),
    # draft emails
    (
        r"gomail\.differences\.emails\.drafts\[(\d+)\]",
        r"gomail.differences.emails.added[?draft == `true`][\1]",
        "gomail draft email index access",
    ),
    (
        r"gomail\.differences\.emails\.drafts\[\?([^\]]+)\]",
        r"gomail.differences.emails.added[?draft == `true` && \1]",
        "gomail draft email with filter",
    ),
    (
        r"length\(gomail\.differences\.emails\.drafts\)",
        r"length(gomail.differences.emails.added[?draft == `true`])",
        "gomail draft email length",
    ),
    (
        r"gomail\.differences\.emails\.drafts",
        r"gomail.differences.emails.added[?draft == `true`]",
        "gomail draft emails array",
    ),

    # FlyUnified patterns
    # The schema shows bookedFlights.added, not bookedFlights directly
    (
        r"flyunified\.differences\.bookedFlights\[(\d+)\]",
        r"flyunified.differences.bookedFlights.added[\1]",
        "flyunified booked flight index access",
    ),
    (
        r"flyunified\.differences\.bookedFlights\[\?([^\]]+)\]",
        r"flyunified.differences.bookedFlights.added[?\1]",
        "flyunified booked flight with filter",
    ),
    (
        r"length\(flyunified\.differences\.bookedFlights\)(?!\.(added|deleted|updated))",
        r"length(flyunified.differences.bookedFlights.added)",
        "flyunified booked flights length",
    ),

    # StaynB patterns - bookings.added is correct, but let's ensure consistency
    # Actually, queries already use staynb.differences.bookings.added which is correct

    # OpenDining patterns - bookings.added is correct

    # GocalenDAR patterns - events.added is correct (uses values(@) for dict)

    # UDriver patterns - pickup/destination are objects, not strings
    # contains(udriver.finalstate.ride.bookedTrip.destination, 'text')
    # should be: contains(udriver.finalstate.ride.bookedTrip.destination.address, 'text')
    (
        r"contains\(udriver\.finalstate\.ride\.bookedTrip\.destination,",
        r"contains(udriver.finalstate.ride.bookedTrip.destination.address,",
        "udriver destination is object, use .address",
    ),
    (
        r"contains\(udriver\.finalstate\.ride\.bookedTrip\.pickup,",
        r"contains(udriver.finalstate.ride.bookedTrip.pickup.address,",
        "udriver pickup is object, use .address",
    ),
    # Also fix in pipe expressions
    (
        r"contains\(pickup,",
        r"contains(pickup.address,",
        "udriver pickup in filter, use .address",
    ),
    (
        r"contains\(destination,",
        r"contains(destination.address,",
        "udriver destination in filter, use .address",
    ),

    # Fix common JMESPath errors
    # > 0 should be >= `1` (no unquoted numbers allowed)
    (
        r"> 0(?!\d)",
        r">= `1`",
        "fix > 0 to >= `1`",
    ),
    (
        r"== 0(?!\d)",
        r"== `0`",
        "fix == 0 to == `0`",
    ),
]


def load_json(path: Path) -> dict:
    """Load JSON from file."""
    with open(path, encoding="utf-8") as f:
        return json.load(f)


def save_json(path: Path, data: dict) -> None:
    """Save JSON to file with pretty formatting."""
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)


def fix_query(query: str, verbose: bool = False) -> tuple[str, list[str]]:
    """
    Apply pattern fixes to a query.

    Returns:
        (fixed_query, list of applied fixes)
    """
    fixed = query
    applied = []

    for pattern, replacement, description in QUERY_FIXES:
        new_fixed = re.sub(pattern, replacement, fixed)
        if new_fixed != fixed:
            applied.append(description)
            if verbose:
                print(f"      Applied: {description}")
            fixed = new_fixed

    return fixed, applied


def process_task(
    task_path: Path,
    dry_run: bool = False,
    verbose: bool = False,
) -> dict:
    """
    Process a single task, fixing query patterns.

    Returns:
        Record of changes made
    """
    task = load_json(task_path)
    task_id = task.get("id", task_path.stem)

    record = {
        "task_id": task_id,
        "queries_checked": 0,
        "queries_fixed": 0,
        "fixes": [],
    }

    evals = task.get("evals", [])
    modified = False

    for i, eval_item in enumerate(evals):
        if eval_item.get("type") != "jmespath":
            continue

        query = eval_item.get("query", "")
        record["queries_checked"] += 1

        fixed_query, applied = fix_query(query, verbose=verbose)

        if fixed_query != query:
            record["queries_fixed"] += 1
            record["fixes"].append({
                "index": i,
                "description": eval_item.get("description", ""),
                "original": query,
                "fixed": fixed_query,
                "applied_fixes": applied,
            })

            if verbose:
                print(f"    [{i}] FIXED: {eval_item.get('description', '')[:50]}...")
                print(f"        Original: {query[:80]}...")
                print(f"        Fixed:    {fixed_query[:80]}...")

            if not dry_run:
                eval_item["query"] = fixed_query
                modified = True

    # Save updated task
    if modified and not dry_run:
        save_json(task_path, task)

    return record


def main():
    parser = argparse.ArgumentParser(
        description="Fix JMESPath query patterns to match actual ground truth schema",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would change without modifying files",
    )
    parser.add_argument(
        "--task",
        type=str,
        help="Process single task by ID",
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Show detailed output",
    )

    args = parser.parse_args()

    # Find task files
    if args.task:
        task_path = TASKS_DIR / f"{args.task}.json"
        if not task_path.exists():
            print(f"Error: Task file not found: {task_path}")
            sys.exit(1)
        task_files = [task_path]
    else:
        task_files = sorted(TASKS_DIR.glob("*.json"))
        task_files = [f for f in task_files if not f.name.endswith(".backup")]

    print(f"Processing {len(task_files)} task files")
    if args.dry_run:
        print("DRY RUN - no files will be modified")
    print()

    # Process tasks
    total_checked = 0
    total_fixed = 0
    all_records = []

    for task_path in task_files:
        task_id = task_path.stem

        record = process_task(
            task_path,
            dry_run=args.dry_run,
            verbose=args.verbose,
        )

        total_checked += record["queries_checked"]
        total_fixed += record["queries_fixed"]

        if record["queries_fixed"] > 0:
            all_records.append(record)
            if not args.verbose:
                print(f"{task_id}: {record['queries_fixed']} queries fixed")

    # Print summary
    print()
    print("=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print(f"Tasks processed:     {len(task_files)}")
    print(f"Queries checked:     {total_checked}")
    print(f"Queries fixed:       {total_fixed}")

    if args.dry_run and total_fixed > 0:
        print()
        print("Run without --dry-run to apply these fixes.")

    # Save report
    if all_records:
        report_path = BASE_DIR / "query_fixes_report.json"
        with open(report_path, "w") as f:
            json.dump({
                "total_checked": total_checked,
                "total_fixed": total_fixed,
                "dry_run": args.dry_run,
                "fixes": all_records,
            }, f, indent=2)
        print(f"\nReport saved to: {report_path}")


if __name__ == "__main__":
    main()
